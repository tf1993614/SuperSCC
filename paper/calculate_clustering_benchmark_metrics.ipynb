{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from SuperSCC import *\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import adjusted_mutual_info_score, rand_score, adjusted_rand_score, normalized_mutual_info_score, accuracy_score, fowlkes_mallows_score\n",
    "from os.path import basename\n",
    "\n",
    "from scipy.stats import gmean, rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_geometric_mean_numpy(values, weight_num = 0.5):\n",
    "    # max_value = np.max(values)\n",
    "    # max_index = np.where(np.array(values) == max_value)[0][0]\n",
    "    # values = np.array(values)\n",
    "    # weights = [(1 - weight_num)/(len(values)-1) for i in range(len(values))]\n",
    "    # weights[max_index] = weight_num\n",
    "    weights = rankdata(values) / np.sum(rankdata(values))\n",
    "    return gmean(values, weights = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaulate_clustering(data, scoring_method, sc3_level, seurat_level):\n",
    "\n",
    "    df_list = list()\n",
    "    \n",
    "    dataset_keys = data[0].keys()\n",
    "\n",
    "    for dataset in dataset_keys:\n",
    "        print(dataset)\n",
    "\n",
    "        y_true = data[0][dataset]\n",
    "        superscc_pred = [str(i) for i in data[1][dataset]]\n",
    "        sc3_pred = data[2][dataset].iloc[:, sc3_level].astype(str).tolist()\n",
    "        seurat_pred = data[3][dataset].loc[:, f\"Cluster_res_{seurat_level}\"].astype(str).tolist()\n",
    "        scanpy_pred = data[4][dataset]\n",
    "        cidr_pred = data[5][dataset].Cluster.astype(str).tolist()\n",
    "        sccaf_pred = data[6][dataset][\"sccaf\"].astype(str).tolist()\n",
    "        scshc_pred = data[7][dataset].clusters.astype(str).tolist()\n",
    "        sclca_pred = data[8][dataset].cluster.astype(str).tolist()\n",
    "        monocle_pred = data[9][dataset].monocle3_cluster.astype(str).tolist()\n",
    "\n",
    "        y_pred = [superscc_pred, sc3_pred, seurat_pred, scanpy_pred, cidr_pred, sccaf_pred, scshc_pred, sclca_pred, monocle_pred]\n",
    "        for key, method in scoring_method.items():\n",
    "            df = pd.DataFrame(columns = [\"dataset\", \"score_method\", \"score\", \"method\"])\n",
    "            method_original = [key for i in range(len(data) - 1)]\n",
    "\n",
    "            score_original = list()\n",
    "            score_list = list()\n",
    "            for i in y_pred:\n",
    "                score = method(y_true, i)\n",
    "                score_list.append(score)\n",
    "            score_original.extend(score_list)\n",
    "\n",
    "            df.score = score_original\n",
    "            df.method = [\"SuperSCC\", \"SC3\", \"Seurat\", \"Scanpy\", \"CIDR\", \"Sccaf\", \"Scshc\", \"Sclca\", \"Monocle\"]\n",
    "            df.score_method = method_original\n",
    "            df.dataset = [dataset for i in range(len(data) - 1)]\n",
    "            df_list.append(df)\n",
    "            \n",
    "    return pd.concat(df_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaulate_clustering2(data, scoring_method, scanpy_level, seurat_level):\n",
    "\n",
    "    df_list = list()\n",
    "    \n",
    "    dataset_keys = data[0].keys()\n",
    "\n",
    "    for dataset in dataset_keys:\n",
    "        print(dataset)\n",
    "\n",
    "        y_true = data[0][dataset]\n",
    "        superscc_pred = [str(i) for i in data[1][dataset]]\n",
    "        seurat_pred = data[2][dataset].loc[:, f\"Cluster_res_{seurat_level}\"].astype(str).tolist()\n",
    "        scanpy_pred = data[3][dataset].loc[:, f\"leiden_{scanpy_level}\"].astype(str).tolist()\n",
    "      \n",
    "\n",
    "        y_pred = [superscc_pred, seurat_pred, scanpy_pred]\n",
    "        for key, method in scoring_method.items():\n",
    "            df = pd.DataFrame(columns = [\"dataset\", \"score_method\", \"score\", \"method\"])\n",
    "            method_original = [key for i in range(3)]\n",
    "\n",
    "            score_original = list()\n",
    "            score_list = list()\n",
    "            for i in y_pred:\n",
    "                score = method(y_true, i)\n",
    "                score_list.append(score)\n",
    "            score_original.extend(score_list)\n",
    "\n",
    "            df.score = score_original\n",
    "            df.method = [\"SuperSCC\",  f\"Seurat_{seurat_level}\", f\"Scanpy_{scanpy_level}\"]\n",
    "            df.score_method = method_original\n",
    "            df.dataset = [dataset for i in range(3)]\n",
    "\n",
    "            df_list.append(df)\n",
    "            \n",
    "    return pd.concat(df_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc(string, num):\n",
    "    return re.split(\"/\", string)[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data location file in\n",
    "data_loc = pd.read_csv(\"/mnt/disk5/zhongmin/superscc/结果位置/结果位置_3.csv\", index_col=0, encoding = \"GBK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the SC3 results\n",
    "# SC3_res_loc = list_files(pattern=\"col_data.csv\", path = \"/mnt/disk5/zhongmin/superscc/师兄整理的肺数据/SC3结果/\", full_name=True, recursive=True)\n",
    "# SC3_res_loc_sub = np.array(sorted(SC3_res_loc))[[ True if i % 2 != 0 else False for i in range(len(SC3_res_loc))]]\n",
    "SC3_res = [*map(lambda x: pd.read_csv(x, index_col=0), data_loc.SC3)]\n",
    "\n",
    "SC3_dict = dict()\n",
    "for idx, i in enumerate(data_loc.SC3):\n",
    "    if re.search(\".+CIDR_结果.+\", i) and re.search(\".+49万拆出的.+\", i):\n",
    "        i = get_loc(i, num = 8)\n",
    "    elif re.search(\".+胚胎.+\", i ):\n",
    "        i = get_loc(i, num = 6)\n",
    "    elif re.search(\".+食管.癌.+\", i):\n",
    "        i = get_loc(i, num = 5)\n",
    "    else:\n",
    "        i = get_loc(i, num = 7)\n",
    "    SC3_dict[i] = SC3_res[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1956670/3399934892.py:8: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  seurat_res_loc[3] = \"/mnt/disk5/zhongmin/superscc/师兄整理的肺数据/seurat结果/Barbry_Leroy_2020/2024-09-02/task1/Barbry_Leroy_metadata.csv\"\n",
      "/tmp/ipykernel_1956670/3399934892.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  i = get_loc(seurat_res_loc[idx], num = 8)\n",
      "/tmp/ipykernel_1956670/3399934892.py:20: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  i = get_loc(seurat_res_loc[idx], num = 7)\n",
      "/tmp/ipykernel_1956670/3399934892.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  i = get_loc(seurat_res_loc[idx], num = 6)\n",
      "/tmp/ipykernel_1956670/3399934892.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  i = get_loc(seurat_res_loc[idx], num = 5)\n"
     ]
    }
   ],
   "source": [
    "# get the Seurat results \n",
    "# seurat_res_loc = list_files(pattern=\".+csv$\", path = \"/mnt/disk5/zhongmin/superscc/师兄整理的肺数据/seurat结果/\", full_name=True)\n",
    "# seurat_res_loc = sorted(seurat_res_loc)\n",
    "# seurat_res_loc.pop(12)\n",
    "# seurat_res_loc_sub = np.array(seurat_res_loc)[[False if i % 2 == 0 else True for i in range(len(seurat_res_loc))]]\n",
    "\n",
    "seurat_res_loc = data_loc.seurat\n",
    "seurat_res_loc[3] = \"/mnt/disk5/zhongmin/superscc/师兄整理的肺数据/seurat结果/Barbry_Leroy_2020/2024-09-02/task1/Barbry_Leroy_metadata.csv\"\n",
    "seurat_res = [*map(lambda x: pd.read_csv(x, index_col=0) if x.endswith(\"csv\") else pd.read_csv(x + \".csv\"), seurat_res_loc)]\n",
    "\n",
    "seurat_dict = dict()\n",
    "for idx, i in enumerate(seurat_res_loc):\n",
    "    if re.search(\".+seurat_结果.+\", i) and re.search(\".+49万拆出的.+\", i):\n",
    "        i = get_loc(seurat_res_loc[idx], num = 8)\n",
    "    elif re.search(\".+胚胎.+\", i ):\n",
    "        i = get_loc(seurat_res_loc[idx], num = 6)\n",
    "    elif re.search(\".+食管.癌.+\", i):\n",
    "        i = get_loc(seurat_res_loc[idx], num = 5)\n",
    "    else:\n",
    "        i = get_loc(seurat_res_loc[idx], num = 7)\n",
    "    seurat_dict[i] = seurat_res[idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scanpy results\n",
    "scanpy_res_loc = data_loc.scanpy\n",
    "scanpy_res = [*map(lambda x: pd.read_csv(x, index_col=0) if x.endswith(\"csv\") else pd.read_csv(x + \".csv\"), scanpy_res_loc)]\n",
    "names = scanpy_res_loc.index.to_list()\n",
    "\n",
    "scanpy_dict = dict()\n",
    "for idx, i in enumerate(scanpy_res_loc):\n",
    "    scanpy_dict[names[idx]] = scanpy_res[idx]  \n",
    "\n",
    "\n",
    "ls = list()\n",
    "for i in scanpy_dict:\n",
    "    if i == \"49万分的pbmc\":\n",
    "        scanpy_dict[\"血液\"] = scanpy_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in scanpy_dict:\n",
    "    if i == \"49万分的大肠\":\n",
    "        scanpy_dict[\"大肠\"] = scanpy_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in scanpy_dict:    \n",
    "    if i == \"食管鳞癌\":\n",
    "        scanpy_dict[\"GSE160269_食管鳞癌\"] = scanpy_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "        \n",
    "for i in scanpy_dict:\n",
    "    if i == \"肺数据集全部取的两万个\":\n",
    "        scanpy_dict[\"所有细胞分2万\"] = scanpy_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in ls:\n",
    "    scanpy_dict.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the CIDR results\n",
    "# cidr_res_loc = list_files(pattern=\".+csv$\", path = \"/mnt/disk5/zhongmin/superscc/师兄整理的肺数据/CIDR结果\", full_name=True)\n",
    "# cidr_res_loc = np.array(cidr_res_loc)[[1, 3, 5, 6, 8, 10, 13, 16, 18, 20]]\n",
    "\n",
    "cidr_res_loc = data_loc.CIDR\n",
    "cidr_res = [*map(lambda x: pd.read_csv(x, index_col=0), cidr_res_loc)]\n",
    "\n",
    "cidr_dict = dict()\n",
    "for idx, i in enumerate(cidr_res_loc):\n",
    "    if re.search(\".+CIDR_结果.+\", i) and re.search(\".+49万拆出的.+\", i):\n",
    "        i = get_loc(i, num = 8)\n",
    "    elif re.search(\".+胚胎.+\", i ):\n",
    "        i = get_loc(i, num = 6)\n",
    "    elif re.search(\".+食管.癌.+\", i):\n",
    "        i = get_loc(i, num = 5)\n",
    "    else:\n",
    "        i = get_loc(i, num = 7)\n",
    "    cidr_dict[i] = cidr_res[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the SuperSCC results\n",
    "superscc_res_pre_loc = data_loc.superscc\n",
    "superscc_res_loc = list()\n",
    "for i in superscc_res_pre_loc:\n",
    "    files = list_files(pattern=\".+pkl$\", path = i, full_name = True, recursive = False)\n",
    "    superscc_res_loc.extend(files)\n",
    "\n",
    "superscc_res = [*map(lambda x: pd.read_pickle(x), sorted(superscc_res_loc))]\n",
    "\n",
    "R_dict = dict()\n",
    "M_dict = dict()\n",
    "F_dict = dict()\n",
    "feature_dict = dict()\n",
    "cluster_dict = dict()\n",
    "\n",
    "select = list()\n",
    "intermediate = dict()\n",
    "for idx, i in enumerate(sorted(superscc_res_loc)):\n",
    "    if re.search(\"师兄整理的肺数据\", i):\n",
    "        i = get_loc(i, num = 7)\n",
    "    elif re.search(\".+胚胎.+\", i ):\n",
    "        i = get_loc(i, num = 6)\n",
    "    elif re.search(\".+食管.癌.+\", i):\n",
    "        i = get_loc(i, num = 5)\n",
    "    elif re.search(\"49万拆出的\", i):\n",
    "        i = get_loc(i, num = 8)\n",
    "\n",
    "    if i not in select:\n",
    "        select.append(i)\n",
    "\n",
    "    if idx % 2 == 0:\n",
    "        i = \"consensus_\" + i\n",
    "    else:\n",
    "        i = \"sub_consensus_\" + i\n",
    "\n",
    "    intermediate[i] = superscc_res[idx]\n",
    "\n",
    "\n",
    "for i in select:\n",
    "    key1 = \"consensus_\" + i\n",
    "    key2 = \"sub_consensus_\" + i\n",
    "\n",
    "    R_dict[i] = intermediate[key1][\"global_cluster_before_merging\"]\n",
    "    M_dict[i] = intermediate[key1][\"global_cluster_after_merging\"][\"labels\"]\n",
    "    F_dict[i] = intermediate[key2][\"merge_labels\"]\n",
    "    feature_dict[i] = pd.DataFrame({\"V1\": [i[0] for i in intermediate[key1][\"global_features_before_merging\"][\"features\"][\"final_feature_selection_by_ensemble\"]]})\n",
    "    cluster_dict[i] = pd.DataFrame({\"V1\": intermediate[key1][\"global_cluster_after_merging\"][\"labels\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scLCA results\n",
    "sclca_files = list_files(path = \"/mnt/disk5/zhongmin/superscc/结果位置/scLCA_results\", pattern = \".+csv$\", recursive = False)\n",
    "file_name = [re.sub(\"_scLCA_results.csv\", \"\", basename(i)) for i in sclca_files]\n",
    "sclca_res = list()\n",
    "\n",
    "for i in sclca_files:\n",
    "    sclca_res.append(pd.read_csv(i))\n",
    "\n",
    "\n",
    "sclca_dict = dict()\n",
    "for idx, i in enumerate(sclca_res):\n",
    "    sclca_dict[file_name[idx]] = i\n",
    "\n",
    "\n",
    "ls = list()\n",
    "for i in sclca_dict:\n",
    "    if i == \"49万分的pbmc\":\n",
    "        sclca_dict[\"血液\"] = sclca_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in sclca_dict:\n",
    "    if i == \"49万分的大肠\":\n",
    "        sclca_dict[\"大肠\"] = sclca_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in sclca_dict:    \n",
    "    if i == \"食管鳞癌\":\n",
    "        sclca_dict[\"GSE160269_食管鳞癌\"] = sclca_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "        \n",
    "for i in sclca_dict:\n",
    "    if i == \"肺数据集全部取的两万个\":\n",
    "        sclca_dict[\"所有细胞分2万\"] = sclca_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in ls:\n",
    "    sclca_dict.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the monocle results\n",
    "monocle_files = list_files(path = \"/mnt/disk5/zhongmin/superscc/结果位置/monocle3/monocle3_results/csv\", pattern = \".+csv$\", recursive = False)\n",
    "file_name = [re.sub(\"_clusters.csv\", \"\", basename(i)) for i in monocle_files]\n",
    "monocle_res = list()\n",
    "\n",
    "for i in monocle_files:\n",
    "    monocle_res.append(pd.read_csv(i))\n",
    "\n",
    "\n",
    "monocle_dict = dict()\n",
    "for idx, i in enumerate(monocle_res):\n",
    "    monocle_dict[file_name[idx]] = i\n",
    "\n",
    "\n",
    "ls = list()\n",
    "for i in monocle_dict:\n",
    "    if i == \"49万分的pbmc\":\n",
    "        monocle_dict[\"血液\"] = monocle_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in monocle_dict:\n",
    "    if i == \"49万分的大肠\":\n",
    "        monocle_dict[\"大肠\"] = monocle_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in monocle_dict:    \n",
    "    if i == \"食管鳞癌\":\n",
    "        monocle_dict[\"GSE160269_食管鳞癌\"] = monocle_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "        \n",
    "for i in monocle_dict:\n",
    "    if i == \"肺数据集全部取的两万个\":\n",
    "        monocle_dict[\"所有细胞分2万\"] = monocle_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in ls:\n",
    "    monocle_dict.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sscaf result\n",
    "data_loc.iloc[2, 21] = '/mnt/disk5/zhongmin/superscc/结果位置/sccaf/Banovich_Kropski_2020数据_sccaf.csv'\n",
    "sccaf_res_loc = data_loc.sccaf\n",
    "\n",
    "\n",
    "sccaf_res = [*map(lambda x: pd.read_csv(x, index_col=0), sccaf_res_loc)]\n",
    "\n",
    "sccaf_dict = dict()\n",
    "for idx, i in enumerate(sccaf_res_loc):\n",
    "    sccaf_dict[sccaf_res_loc.index.values[idx]] = sccaf_res[idx] \n",
    "\n",
    "ls = list()\n",
    "for i in sccaf_dict:\n",
    "    if i == \"49万分的pbmc\":\n",
    "        sccaf_dict[\"血液\"] = sccaf_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in sccaf_dict:\n",
    "    if i == \"49万分的大肠\":\n",
    "        sccaf_dict[\"大肠\"] = sccaf_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in sccaf_dict:    \n",
    "    if i == \"食管鳞癌\":\n",
    "        sccaf_dict[\"GSE160269_食管鳞癌\"] = sccaf_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "        \n",
    "for i in sccaf_dict:\n",
    "    if i == \"肺数据集全部取的两万个\":\n",
    "        sccaf_dict[\"所有细胞分2万\"] = sccaf_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in ls:\n",
    "    sccaf_dict.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sc-SHC result\n",
    "scshc_res_loc = data_loc.sc_SHC\n",
    "scshc_res = [*map(lambda x: pd.read_csv(x, index_col=0), scshc_res_loc)]\n",
    "scshc_dict = dict()\n",
    "\n",
    "for idx, i in enumerate(scshc_res_loc):\n",
    "    data = scshc_res[idx] \n",
    "    data.columns = [\"clusters\"]\n",
    "    scshc_dict[scshc_res_loc.index.values[idx]] = data\n",
    "\n",
    "\n",
    "ls = list()\n",
    "for i in scshc_dict:\n",
    "    if i == \"49万分的pbmc\":\n",
    "        scshc_dict[\"血液\"] = scshc_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in scshc_dict:\n",
    "    if i == \"49万分的大肠\":\n",
    "        scshc_dict[\"大肠\"] = scshc_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in scshc_dict:    \n",
    "    if i == \"食管鳞癌\":\n",
    "        scshc_dict[\"GSE160269_食管鳞癌\"] = scshc_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "        \n",
    "for i in scshc_dict:\n",
    "    if i == \"肺数据集全部取的两万个\":\n",
    "        scshc_dict[\"所有细胞分2万\"] = scshc_dict[i]\n",
    "        ls.append(i)\n",
    "        break\n",
    "\n",
    "for i in ls:\n",
    "    scshc_dict.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original annotation for each dataset\n",
    "orig_finest = dict()\n",
    "orig_lv1 = dict()\n",
    "orig_lv2 = dict()\n",
    "orig_lv3 = dict()\n",
    "orig_lv4 = dict()\n",
    "\n",
    "for i in SC3_dict.keys():\n",
    "    try:\n",
    "        orig_finest[i] = seurat_dict[i].ann_finest_level.tolist()\n",
    "        orig_lv1[i] = seurat_dict[i].ann_level_1.tolist()\n",
    "        orig_lv2[i] = seurat_dict[i].ann_level_2.tolist()\n",
    "        orig_lv3[i] = seurat_dict[i].ann_level_3.tolist()\n",
    "        orig_lv4[i] = seurat_dict[i].ann_level_4.tolist()\n",
    "    except:\n",
    "        if i == \"血液\": \n",
    "            file = pd.read_csv(\"/mnt/disk5/zhongmin/superscc/49万拆出的/sup/未去批次效应数据/正常血液组织数据2万_metadata_整理细胞类型.csv\", index_col=0)\n",
    "            orig_lv2[i] = file.loc[:, \"level1_celltype\"].tolist()\n",
    "        elif i == \"大肠\":\n",
    "            file = pd.read_csv(\"/mnt/disk5/zhongmin/superscc/49万拆出的/sup/未去批次效应数据/正常大肠组织数据2万_metadata_整理细胞类型.csv\", index_col=0)\n",
    "            orig_lv2[i] = file.loc[:, \"level1_celltype\"].tolist()\n",
    "        elif i == \"D034\":\n",
    "            file = pd.read_csv(\"/mnt/disk5/zhongmin/superscc/胚胎数据/D034/未去批次效应数据/没有去除批次效应_2万所有数据metadata_2_整理细胞类型.csv\", index_col=0)\n",
    "            orig_lv2[i] = file.loc[:, \"level1_celltype\"].tolist()\n",
    "        elif i == \"GSE160269_食管鳞癌\":\n",
    "            orig_lv2[i] = seurat_dict[i].annotated_type.tolist()\n",
    "        elif i == \"D009\":\n",
    "            orig_lv2[i] = seurat_dict[i].cell_type.tolist()\n",
    "        elif i == \"D022\":\n",
    "            orig_lv2[i] = seurat_dict[i].broad_celltype.tolist()\n",
    "        elif i == \"GSE136831_Kaminski_2020\":\n",
    "            orig_lv2[i] = seurat_dict[i].CellType_Category.tolist()\n",
    "        elif i == \"GSE161382_Sun_2020\":\n",
    "            orig_lv2[i] = seurat_dict[i].lineage.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# check all results generated by different methods on different datasets are read in \n",
    "for i in (R_dict.keys(), M_dict.keys(), F_dict.keys(), seurat_dict.keys(), SC3_dict.keys(), cidr_dict.keys(), sccaf_dict.keys(), orig_lv2.keys(), scshc_dict.keys(), sclca_dict.keys(), monocle_dict.keys()):\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ARI, AMI, FMI, NMI scores per dataset per method\n",
    "res = evaulate_clustering([orig_lv2, M_dict, SC3_dict, seurat_dict, R_dict, cidr_dict, sccaf_dict, scshc_dict, sclca_dict, monocle_dict], scoring_method = {\"ARI\": adjusted_rand_score, \"NMI\": normalized_mutual_info_score, \"AMI\": adjusted_mutual_info_score, \"FMI\": fowlkes_mallows_score} , sc3_level = 1, seurat_level = 0.8)\n",
    "res.to_csv(f\"/home/fengtang/jupyter_notebooks/working_script/evulate_clustering/3rd_submission/lv2_clustering_performance_3nd_submission_{record_time()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n",
      "血液\n",
      "大肠\n",
      "Banovich_Kropski_2020\n",
      "Barbry_Leroy_2020\n",
      "D009\n",
      "D022\n",
      "D034\n",
      "GSE136831_Kaminski_2020\n",
      "GSE161382_Sun_2020\n",
      "Krasnow_2020\n",
      "Lafyatis_Rojas_2019\n",
      "Meyer_2019\n",
      "Misharin_2021\n",
      "Misharin_Budinger_2018\n",
      "Nawijn_2021\n",
      "Teichmann_Meyer_2019\n",
      "所有细胞分2万\n",
      "GSE160269_食管鳞癌\n"
     ]
    }
   ],
   "source": [
    "# get the ARI, AMI, FMI, NMI scores per dataset for Seurat and Scanpy clusterings under resolution rang from 0.1 to 1\n",
    "res_list = list()\n",
    "for resolution in np.linspace(0.1, 1, 10):\n",
    "    if np.isclose(resolution, 1) == False:\n",
    "        resolution = np.around(resolution, 1)\n",
    "        df = evaulate_clustering2([orig_lv2, M_dict,  seurat_dict, scanpy_dict], scoring_method = {\"ARI\": adjusted_rand_score, \"NMI\": normalized_mutual_info_score, \"AMI\": adjusted_mutual_info_score, \"FMI\": fowlkes_mallows_score} , scanpy_level = resolution, seurat_level = resolution)\n",
    "        df.loc[:, \"resolution\"] = resolution\n",
    "        res_list.append(df)\n",
    "    else:\n",
    "        resolution_1 = 1\n",
    "        resolution_2 = 1.0\n",
    "        df = evaulate_clustering2([orig_lv2, M_dict,  seurat_dict, scanpy_dict], scoring_method = {\"ARI\": adjusted_rand_score, \"NMI\": normalized_mutual_info_score, \"AMI\": adjusted_mutual_info_score, \"FMI\": fowlkes_mallows_score} , scanpy_level = resolution_2, seurat_level = resolution_1)\n",
    "        df.loc[:, \"resolution\"] = resolution\n",
    "        res_list.append(df)\n",
    "\n",
    "combined_res = pd.concat(res_list, axis = 0)\n",
    "# combined_res_sub = combined_res.loc[combined_res.method != \"SuperSCC\", :]\n",
    "# combined_res_sub.loc[:, \"method\"] = [re.findall(\"[^_]+\", i)[0] for i in combined_res_sub.method.tolist()]\n",
    "# combined_res_group = combined_res_sub.groupby([\"dataset\", \"score_method\", \"method\"])\n",
    "\n",
    "# gmean_res = list()\n",
    "# for group in combined_res_group.groups.keys():\n",
    "#     data = combined_res_group.get_group(group)\n",
    "#     score = data.score.tolist()\n",
    "#     average = weighted_geometric_mean_numpy(score)\n",
    "\n",
    "#     dataset = data.dataset.unique()[0]\n",
    "#     score_method = data.score_method.unique()[0]\n",
    "#     method = data.method.unique()[0]\n",
    "\n",
    "#     gmean_res.append(pd.DataFrame({\"dataset\": dataset, \"score_method\": score_method, \"method\": method, \"score\": average}, index=[0]))\n",
    "\n",
    "# gmean_res = pd.concat(gmean_res, axis = 0)\n",
    "# gmean_res.index = range(gmean_res.shape[0])\n",
    "\n",
    "# superscc_output = combined_res.loc[combined_res.method == \"SuperSCC\", :].sort_values([\"dataset\", \"score_method\"]).drop_duplicates(keep = \"first\")\n",
    "# gmean_res = pd.concat([gmean_res, superscc_output], axis = 0)\n",
    "\n",
    "# gmean_res.to_csv(f\"/home/fengtang/jupyter_notebooks/working_script/evulate_clustering/3rd_submission/Aggregate_mean_scanpy_seurat_under_different_resolution_{record_time()}.csv\")\n",
    "\n",
    "combined_res.to_csv(f\"/home/fengtang/jupyter_notebooks/working_script/evulate_clustering/3rd_submission/Aggregate_mean_scanpy_seurat_under_different_resolution_{record_time()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SuperSCC', 'Seurat_0.1', 'Scanpy_0.1', 'Seurat_0.2', 'Scanpy_0.2',\n",
       "       'Seurat_0.3', 'Scanpy_0.3', 'Seurat_0.4', 'Scanpy_0.4',\n",
       "       'Seurat_0.5', 'Scanpy_0.5', 'Seurat_0.6', 'Scanpy_0.6',\n",
       "       'Seurat_0.7', 'Scanpy_0.7', 'Seurat_0.8', 'Scanpy_0.8',\n",
       "       'Seurat_0.9', 'Scanpy_0.9', 'Seurat_1', 'Scanpy_1.0'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_res.method.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SuperSCC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
