{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SuperSCC as scc\n",
    "from os import mkdir, chdir, getcwd\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file loc \n",
    "file_loc = pd.read_csv(\"/mnt/disk5/zhongmin/superscc/结果位置/结果位置_3.csv\")\n",
    "\n",
    "file_loc = pd.DataFrame(file_loc.loc[file_loc.数据集.isin(['Banovich_Kropski_2020', 'Barbry_Leroy_2020', 'Krasnow_2020', 'Lafyatis_Rojas_2019', 'Meyer_2019', 'Misharin_2021', 'Misharin_Budinger_2018', 'Nawijn_2021', 'Teichmann_Meyer_2019']), [\"数据集\", \"取到的2w子集文件的位置\"]])\n",
    "\n",
    "raw_cell_type_file_loc = list_files(path = \"/home/fengtang/jupyter_notebooks/working_script/evulate_clustering/cell_type_info/raw\", pattern=\".+csv$\", full_name=True)\n",
    "\n",
    "finest_cell_type_file_loc = list_files(path = \"/home/fengtang/jupyter_notebooks/working_script/evulate_clustering/cell_type_info/finest\", pattern=\".+finest.+csv$\", full_name=True)\n",
    "\n",
    "file_loc.loc[:, \"raw_cell_type\"] = [raw_cell_type_file_loc[2], raw_cell_type_file_loc[4], raw_cell_type_file_loc[6], raw_cell_type_file_loc[0], raw_cell_type_file_loc[5], raw_cell_type_file_loc[-2], raw_cell_type_file_loc[1], raw_cell_type_file_loc[-1], raw_cell_type_file_loc[3]]\n",
    "file_loc.loc[:, \"finest_cell_type\"] = [finest_cell_type_file_loc[-2], finest_cell_type_file_loc[3], finest_cell_type_file_loc[-3], finest_cell_type_file_loc[1], finest_cell_type_file_loc[0], finest_cell_type_file_loc[-4], finest_cell_type_file_loc[2], finest_cell_type_file_loc[-1], finest_cell_type_file_loc[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, data2, filename, wk_dir, query_data = None, train_on = \"single\"):\n",
    "\n",
    "    # read data in\n",
    "    print(f\"{scc.record_time()} read expression matrix in\")\n",
    "    if train_on == \"single\":\n",
    "        data = pd.read_csv(data, index_col=0)\n",
    "    else:\n",
    "        data = data\n",
    "\n",
    "    # specify the filename\n",
    "    filename = filename \n",
    "\n",
    "    # read cell label in\n",
    "    print(f\"{scc.record_time()} read cell type information in\")\n",
    "    if train_on == \"single\":\n",
    "        label = pd.read_csv(data2, index_col=0)\n",
    "    else:\n",
    "        label = data2\n",
    "\n",
    "    # replace NA values \n",
    "    label = label.replace(np.nan, \"Unknown\")\n",
    "\n",
    "    # create log_file object\n",
    "    my_logger = log_file(\"model_training_and_prediction\", \"a\")\n",
    "\n",
    "    if train_on == \"single\":\n",
    "        # split train dataset and test dataset index\n",
    "        print(f\"{scc.record_time()} split dataset for training and testing\")\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, label, test_size= 0.3)\n",
    "\n",
    "        # write train dataset and test dataset\n",
    "        Xtrain.loc[:, \"cell_type\"] = Ytrain.cell_type.values\n",
    "        Xtrain_index = pd.DataFrame(Xtrain.loc[:, \"cell_type\"])\n",
    "\n",
    "        Xtest.loc[:, \"cell_type\"] = Ytest.cell_type.values\n",
    "        Xtest_index = pd.DataFrame(Xtest.loc[:, \"cell_type\"])\n",
    "\n",
    "        Xtrain_index.to_csv(f\"{filename}_train_dataset.csv\")\n",
    "        Xtest_index.to_csv(f\"{filename}_test_dataset.csv\")\n",
    "    else:\n",
    "        Xtrain = data\n",
    "\n",
    "    # do normalization on train dataset\n",
    "    if train_on == \"single\":\n",
    "        print(f\"{scc.record_time()} doing normalization on training dataset\")\n",
    "        Xtrain = sc.AnnData(Xtrain.select_dtypes(\"number\"))\n",
    "        sc.pp.normalize_total(Xtrain, target_sum = 1e4)\n",
    "        sc.pp.log1p(Xtrain)\n",
    "\n",
    "        Xtrain2 = pd.DataFrame(Xtrain.X)\n",
    "        Xtrain2.columns = Xtrain.var_names\n",
    "        Xtrain2.index = Xtrain.obs_names\n",
    "        Xtrain2.loc[:, \"cell_type\"] = Ytrain.cell_type.values\n",
    "    else:\n",
    "        print(f\"{scc.record_time()} doing normalization on training dataset\")\n",
    "        Xtrain = sc.AnnData(Xtrain.select_dtypes(\"number\"))\n",
    "        sc.pp.normalize_total(Xtrain, target_sum = 1e4)\n",
    "        sc.pp.log1p(Xtrain)\n",
    "\n",
    "        Xtrain2 = pd.DataFrame(Xtrain.X)\n",
    "        Xtrain2.columns = Xtrain.var_names\n",
    "        Xtrain2.index = Xtrain.obs_names\n",
    "        Xtrain2.loc[:, \"cell_type\"] = data2.cell_type.values\n",
    "\n",
    "    if train_on == \"single\":\n",
    "        # do normalization on test dataset\n",
    "        print(f\"{scc.record_time()} doing normalization on testing dataset\")\n",
    "        Xtest= sc.AnnData(Xtest.select_dtypes(\"number\"))\n",
    "        sc.pp.normalize_total(Xtest, target_sum = 1e4)\n",
    "        sc.pp.log1p(Xtest)\n",
    "\n",
    "        Xtest2 = pd.DataFrame(Xtest.X)\n",
    "        Xtest2.columns = Xtest.var_names\n",
    "        Xtest2.index = Xtest.obs_names\n",
    "        Xtest2.loc[:, \"cell_type\"] = Ytest.cell_type.values\n",
    "    else:\n",
    "        Xtest = query_data\n",
    "        print(f\"{scc.record_time()} doing normalization on testing dataset\")\n",
    "        Xtest= sc.AnnData(Xtest.select_dtypes(\"number\"))\n",
    "        sc.pp.normalize_total(Xtest, target_sum = 1e4)\n",
    "        sc.pp.log1p(Xtest)\n",
    "\n",
    "        Xtest2 = pd.DataFrame(Xtest.X)\n",
    "        Xtest2.columns = Xtest.var_names\n",
    "        Xtest2.index = Xtest.obs_names\n",
    "        Xtest2.loc[:, \"cell_type\"] = query_data.cell_type.values\n",
    "\n",
    "    \n",
    "\n",
    "    # run feature_selection\n",
    "    print(f\"{scc.record_time()} run feature selection\")\n",
    "    res1 = scc.feature_selection(Xtrain2.copy(), label_column = \"cell_type\", model = \"svm\", filename = filename, normalization_method = \"Min-Max\", logger = my_logger, save = True)\n",
    "    features = [i[0] for i in res1[\"final_feature_selection_by_ensemble\"]]\n",
    "\n",
    "    # run model training\n",
    "    print(f\"{scc.record_time()} run model training\")\n",
    "    res2 = scc.model_training(Xtrain2.copy(), label_column = \"cell_type\", features = features, model = \"svm\", normalization_method = \"Min-Max\", filename = filename, save = True, logger = my_logger)\n",
    "\n",
    "    # run prediction\n",
    "    print(f\"{scc.record_time()} run prediction\")\n",
    "    pred = scc.predict_label(Xtest2, models = \".+training_model.+pkl$\", wk_dir = wk_dir, save=True, logger = my_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-validation\n",
    "# train on 70% data of a dataset, predict on 30% data of the corresponding dataset\n",
    "\n",
    "data_loc = file_loc.iloc[:, 1].values\n",
    "data2_loc =  file_loc.iloc[:, 3].values\n",
    "filenames = file_loc.iloc[:, 0].values\n",
    "\n",
    "os.chdir(\"/mnt/disk5/zhongmin/superscc/label_transfer/代码/SuperSCC/\")\n",
    "for i in filenames:\n",
    "    if not exists(i):\n",
    "        mkdir(\"./\" + i)\n",
    "\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    os.chdir(filenames[i])\n",
    "    wk_dir = os.getcwd()\n",
    "    main(data = data_loc[i], data2 = data2_loc[i], filename = filenames[i], wk_dir = wk_dir)\n",
    "    print(wk_dir)\n",
    "    os.chdir(\"/mnt/disk5/zhongmin/superscc/label_transfer/代码\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_451058/137759856.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_count.loc[:, \"cell_type\"] = sub_cell_type.cell_type.values\n"
     ]
    }
   ],
   "source": [
    "# cross-validation\n",
    "# train on one individual datasets \n",
    "# then predict on another dataset\n",
    "cell_index = pd.read_csv(\"/home/fengtang/jupyter_notebooks/working_script/evulate_clustering/cell_index_from_each_study.csv\", index_col=0)\n",
    "cell_type = pd.read_csv(\"/mnt/disk5/zhongmin/superscc/师兄整理的肺数据/未去批次效应数据/没有去除批次效应_所有细胞分2万metadata.csv\", index_col = 0)\n",
    "\n",
    "count_matrix = pd.read_csv('/mnt/disk5/zhongmin/superscc/师兄整理的肺数据/未去批次效应couns数据/没有去除批次效应_所有细胞分2万.csv', index_col=0)\n",
    "train_cell_index = cell_index.loc[cell_index.study.isin([\"Misharin_Budinger_2018\", \"Misharin_2021\", \"Meyer_2019\", \"Seibold_2020\", \"Jain_Misharin_2021\"])]\n",
    "\n",
    "sub_count = count_matrix.loc[count_matrix.index.isin(train_cell_index.index)]\n",
    "sub_cell_type = pd.DataFrame(cell_type.loc[cell_type.index.isin(train_cell_index.index), \"ann_finest_level\"])\n",
    "sub_cell_type.columns = [\"cell_type\"]\n",
    "\n",
    "sub_count.loc[:, \"cell_type\"] = sub_cell_type.cell_type.values\n",
    "\n",
    "# prepare query dataset\n",
    "query_file_loc = file_loc.loc[file_loc.数据集.isin([\"Banovich_Kropski_2020\", \"Barbry_Leroy_2020\", \"Krasnow_2020\", \"Lafyatis_Rojas_2019\", \"Nawijn_2021\", \"Teichmann_Meyer_2019\"])]\n",
    "\n",
    "parent_dir = \"/home/fengtang/jupyter_notebooks/working_script/label_transfer/SuperSCC\"\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "    \n",
    "for i in range(query_file_loc.shape[0]):\n",
    "    query_matrix = pd.read_csv(query_file_loc.iloc[i, 1], index_col=0)\n",
    "    query_label = pd.read_csv(query_file_loc.iloc[i, 3], index_col=0)\n",
    "    query_matrix.loc[:, \"cell_type\"] = query_label.cell_type.values\n",
    "    filename = query_file_loc.iloc[i, 0]\n",
    "\n",
    "    if not exists(filename):\n",
    "        mkdir(\"./\" + filename)\n",
    "    \n",
    "    os.chdir(filename)\n",
    "\n",
    "    main(data = sub_count, data2 = sub_cell_type, filename = filename, query_data = query_matrix, wk_dir = getcwd(), train_on = \"multi\")\n",
    "\n",
    "    os.chdir(parent_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
