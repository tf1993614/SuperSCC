{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import re\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "import os \n",
    "from collections import Counter\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/76361/OneDrive/桌面/GPT-based feature evulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path, pattern, recursive = True, full_name = True):\n",
    "    \"\"\"\n",
    "    A function to produce a list of the names of files in the named directory.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    def list_files_core(current_path = path, current_pattern = pattern, current_recursive = recursive, current_full_name = full_name):\n",
    "        nonlocal output\n",
    "        files = os.listdir(current_path)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(current_path, file)\n",
    "            \n",
    "            if os.path.isdir(file_path) and current_recursive:\n",
    "                list_files_core(file_path, current_pattern, current_recursive, current_full_name)\n",
    "            \n",
    "            else:\n",
    "                if re.search(current_pattern, file):\n",
    "                    if full_name == True:\n",
    "                        file = os.path.join(current_path, file)\n",
    "                        output.append(file)\n",
    "                    else:\n",
    "                        output.append(file)\n",
    "    list_files_core()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SuperSCC markers\n",
    "superscc_markers = pd.read_pickle(\"SuperSCC_default_retrieving_method_top_20_markers.pkl\")\n",
    "\n",
    "# scanpy wilcox test markers\n",
    "scanpy_wilcox_markers = pd.read_pickle(\"scanpy_wilicox_test_top_20_markers.pkl\")\n",
    "\n",
    "# scanpy t test markers\n",
    "scanpy_t_markers = pd.read_pickle(\"scanpy_t_test_top_20_markers.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the id2symbol file\n",
    "reference = pd.read_csv(\"human_id2symbol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2symbol(reference, query, multi_select = \"first\"):\n",
    "     query = pd.DataFrame({\"gene_id\": query})\n",
    "\n",
    "     query = query.join(reference.set_index(\"gene_id\"), how = \"left\", on = \"gene_id\")\n",
    "     return query.gene_name.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No satified markers with default cutoff in Dataset 'D034' for cell type 'regulatory T cell'\n",
      "No satified markers with default cutoff in Dataset 'D034' for cell type 'mast cell'\n"
     ]
    }
   ],
   "source": [
    "# convert IDs to gene symbols for SuperSCC markers\n",
    "superscc_symbols = dict()\n",
    "for i in superscc_markers:\n",
    "    for idx, j in enumerate(superscc_markers[i]):\n",
    "        query = superscc_markers[i][j][\"feature\"].values\n",
    "        try:\n",
    "            condition = query[0]\n",
    "        except:\n",
    "            print(f\"No satified markers with default cutoff in Dataset '{i}' for cell type '{j}'\")\n",
    "            continue\n",
    "        \n",
    "        if condition.startswith(\"ENSG\"):\n",
    "            symbol = id2symbol(reference, query)\n",
    "        else:\n",
    "            symbol = list(query)\n",
    "\n",
    "        if idx == 0:\n",
    "            superscc_symbols[i] = {j: symbol}\n",
    "        else:\n",
    "            superscc_symbols[i].update({j: symbol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert IDs to gene symbols for scanpy markers\n",
    "scanpy_wilcox_symbols = dict()\n",
    "for i in scanpy_wilcox_markers:\n",
    "    for idx, j in enumerate(scanpy_wilcox_markers[i]):\n",
    "        query = scanpy_wilcox_markers[i][j][\"names\"].values\n",
    "\n",
    "        try:\n",
    "            condition = query[0]\n",
    "        except:\n",
    "            print(f\"No satified markers with default cutoff in Dataset '{i}' for cell type '{j}'\")\n",
    "            continue\n",
    "\n",
    "        if condition.startswith(\"ENSG\"):\n",
    "            symbol = id2symbol(reference, query)\n",
    "        else:\n",
    "            symbol = list(query)\n",
    "\n",
    "\n",
    "        if idx == 0:\n",
    "            scanpy_wilcox_symbols[i] = {j: symbol}\n",
    "        else:\n",
    "            scanpy_wilcox_symbols[i].update({j: symbol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the seurat markers\n",
    "files = list_files(path=\"C:/Users/76361/OneDrive/桌面/GPT-based feature evulation/seurat_res\", pattern=\".+csv$\")\n",
    "\n",
    "seurat_wilcox_markers = dict()\n",
    "\n",
    "for file in files:\n",
    "    csv = pd.read_csv(file)\n",
    "    csv = csv.loc[(csv.p_val_adj < 0.05) & (csv.avg_log2FC > 1)].sort_values(\"p_val_adj\")\n",
    "    name = re.sub(\"_seurat_feature.csv\", \"\", basename(file))\n",
    "\n",
    "    group_csv = csv.groupby(\"cluster\")\n",
    "\n",
    "    for idx, i in enumerate(group_csv.groups.keys()):\n",
    "        markers = group_csv.get_group(i).head(20).gene.values.tolist()\n",
    "\n",
    "        if idx == 0:\n",
    "            seurat_wilcox_markers[name] = {i: markers}\n",
    "        else:\n",
    "            seurat_wilcox_markers[name].update({i: markers})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert IDs to gene symbols for seurat markers\n",
    "seurat_wilcox_symbols = dict()\n",
    "\n",
    "for i in seurat_wilcox_markers:\n",
    "    for idx, j in enumerate(seurat_wilcox_markers[i]):\n",
    "        query = seurat_wilcox_markers[i][j]\n",
    "\n",
    "        try:\n",
    "            condition = query[0]\n",
    "            print(condition)\n",
    "        except:\n",
    "            print(f\"No satified markers with default cutoff in Dataset '{i}' for cell type '{j}'\")\n",
    "            continue\n",
    "\n",
    "        if condition.startswith(\"ENSG\"):\n",
    "            symbol = id2symbol(reference, query)\n",
    "        else:\n",
    "            symbol = query\n",
    "\n",
    "\n",
    "        if idx == 0:\n",
    "            seurat_wilcox_symbols[i] = {j: symbol}\n",
    "        else:\n",
    "            seurat_wilcox_symbols[i].update({j: symbol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep shared keys between all algorithem\n",
    "shared_keys = dict()\n",
    "\n",
    "for i in superscc_symbols.keys():\n",
    "    for idx, j in enumerate(superscc_symbols[i].keys()):\n",
    "        if j in scanpy_wilcox_symbols[i].keys() and len(superscc_symbols[i][j]) != 0:\n",
    "            if idx == 0:\n",
    "                shared_keys[i] = {j: 0}\n",
    "            else:\n",
    "                shared_keys[i].update({j: 0})\n",
    "                \n",
    "new_seurat = dict()\n",
    "for i in shared_keys:\n",
    "    for idx, j in enumerate(shared_keys[i]):\n",
    "        if idx == 0:\n",
    "            new_seurat[i] = {j : seurat_wilcox_symbols[i][j]}\n",
    "        else:\n",
    "             new_seurat[i].update({j : seurat_wilcox_symbols[i][j]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the home dir \n",
    "home = \"C:/Users/76361/OneDrive/桌面/GPT-based feature evulation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the output class\n",
    "class Output(BaseModel):\n",
    "    GenesetName: list[str]\n",
    "    RelevantGeneRatio: list[float]\n",
    "    Pvalue: list[float]\n",
    "    BiologicalRelevanceScore: list[str]\n",
    "    Summary: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "for key1 in shared_keys:\n",
    "\n",
    "    if not os.path.exists(key1):\n",
    "        os.mkdir(key1)\n",
    "        os.chdir(key1)\n",
    "    else:\n",
    "        os.chdir(key1)\n",
    "\n",
    "    for key2 in shared_keys[key1]:\n",
    "\n",
    "        print(f\"Processing with {key1}_{key2}\")\n",
    "\n",
    "        client = OpenAI(api_key=\"********\") # asterisk represents the API key\n",
    "\n",
    "        SYSTEM_CONTENT = \\\n",
    "        \"\"\"\n",
    "        Suppose you are an insightful biologist tasked with evaluating two gene sets to determine which one better reflects the underlying biological function. \n",
    "        You will use both Gene Ontology and KEGG databases to design scoring metrics. \n",
    "        If cell type labels are provided, evaluate which gene set is a better representative of that specific cell type. \n",
    "        Gene Set Format: Input gene sets can be in gene symbol or Ensembl ID format. If Ensembl IDs are provided, automatically convert them to gene symbols, ensuring the accuracy of the conversion. \n",
    "        Evaluation Method: Measure the ratio of relevant genes (genes associated with the cell type) in each gene set. \n",
    "        For this comparison, use a statistical test like Fisher’s exact test (or chi-squared test if applicable), \n",
    "        ensuring that the calculation detail is shown and accuracy is guaranteed (e.g. make sure 2x2 contingency table is used for Fisher’s exact test ). \n",
    "        Also the evaluation should be independent of gene set order. Normalize the ratio to account for any differences in gene set size. \n",
    "        Scoring Metrics: Relevant Gene Ratio: The proportion of relevant genes in each gene set. \n",
    "        Biological Relevance Score: Derived from Gene Ontology and KEGG pathways, reflecting the biological function of the gene set. \n",
    "        Statistical Test Result: Provide the p-value from the test comparing the relevant gene ratios between the two gene sets. \n",
    "        Output: Present the results in a CSV file with the following columns: Gene Set Name: The name of the gene set being evaluated. \n",
    "        Gene List: Comma-separated list of genes in the set. Relevant Gene Ratio: The proportion of relevant genes in the set. \n",
    "        P-value: From the statistical comparison. Biological Relevance Score: Based on Gene Ontology and KEGG database associations. \n",
    "        Summary: A brief summary of the gene functions or pathway associations for each gene in the gene set. \n",
    "        Cutoff Determination: Determine the cutoff for gene relevance based on the data distribution (e.g., by using the median or 75th percentile of relevant genes across the dataset). \n",
    "\n",
    "        \"\"\"\n",
    "        messages = [{'role': 'system', 'content': SYSTEM_CONTENT}]\n",
    "\n",
    "        USER_CONTENT = \\\n",
    "        f\"\"\"\n",
    "        cell type: {key2}\n",
    "\n",
    "        gene set1: {superscc_symbols[key1][key2]}\n",
    "\n",
    "        gene set2: {new_seurat[key1][key2]} \n",
    "        \"\"\"\n",
    "        # alternatively, gene set2:{scanpy_wilcox_symbols[key1][key2]}\n",
    "\n",
    "        messages.append({'role': 'user', 'content': USER_CONTENT})\n",
    "\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model = \"gpt-4o-2024-11-20\",\n",
    "            messages = messages,\n",
    "            # max_tokens = 10000,\n",
    "            # top_p = 0.8,\n",
    "            )\n",
    "\n",
    "        detail = response.choices[0].message.content\n",
    "\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-2024-11-20\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert at structured data extraction. You will be given unstructured text from the input and should convert it into the given structure. \"},\n",
    "                {\"role\": \"user\", \"content\": detail}\n",
    "                    ],\n",
    "            response_format=Output,\n",
    "            )\n",
    "        \n",
    "        summary =  completion.choices[0].message.content\n",
    "\n",
    "        if re.search(\"/\", key2):\n",
    "            key2 = re.sub(\"/\", \"-\", key2)\n",
    "            \n",
    "        try:\n",
    "            with open(f\"{key1}_{key2}_detail_result.txt\", \"w\") as file:\n",
    "                try: \n",
    "                    file.write(detail)\n",
    "                except:\n",
    "                    detail = detail.encode(\"utf-8\", errors = \"ignore\").decode(\"utf-8\")\n",
    "                    file.write(detail)\n",
    "\n",
    "            with open(f\"{key1}_{key2}_summary_result.txt\", \"w\") as file:\n",
    "                file.write(summary)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    os.chdir(home)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
